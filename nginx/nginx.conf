events {
    worker_connections 1024;
}

http {
    log_format custom '$remote_addr - $remote_user [$time_local] '
                      '"$request" $status $body_bytes_sent '
                      '"$http_referer" "$http_user_agent" '
                      'API_KEY: $http_authorization';

    access_log /var/log/nginx/access.log custom;
    error_log /var/log/nginx/error.log;

    # Map to check API key - supports multiple keys
    map $http_authorization $api_key_valid {
        default 0;
        "Bearer sk-oatisawesome-2024-ml-api" 1;
        "Bearer sk-0at!sAw3s0m3-2024-ml-v2" 1;
    }

    upstream ollama {
        server ollama:11434;
    }

    server {
        listen 80;
        server_name _;

        # Enable large body sizes for model requests
        client_max_body_size 100M;
        client_body_timeout 300s;

        # Proxy timeouts for long-running requests
        proxy_connect_timeout 300s;
        proxy_send_timeout 300s;
        proxy_read_timeout 300s;

        # Add CORS headers
        add_header 'Access-Control-Allow-Origin' '*' always;
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE' always;
        add_header 'Access-Control-Allow-Headers' 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization' always;
        add_header 'Access-Control-Expose-Headers' 'Content-Length,Content-Range' always;

        # Handle preflight requests
        if ($request_method = 'OPTIONS') {
            return 204;
        }

        # Health check endpoint (no auth required)
        location /health {
            return 200 "OK\n";
            add_header Content-Type text/plain;
        }

        # OpenAI-compatible endpoints
        location ~ ^/v1/(chat/completions|completions|embeddings|models) {
            # Check API key
            if ($api_key_valid = 0) {
                return 401 '{"error": {"message": "Invalid API key", "type": "invalid_request_error", "code": "invalid_api_key"}}';
                add_header Content-Type application/json;
            }

            # Map OpenAI endpoints to Ollama endpoints
            rewrite ^/v1/chat/completions$ /api/chat break;
            rewrite ^/v1/completions$ /api/generate break;
            rewrite ^/v1/embeddings$ /api/embeddings break;
            rewrite ^/v1/models$ /api/tags break;

            proxy_pass http://ollama;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Support for streaming responses
            proxy_set_header Connection '';
            proxy_buffering off;
            proxy_cache off;
            chunked_transfer_encoding on;
        }

        # Direct Ollama API access (for debugging)
        location /api/ {
            # Check API key
            if ($api_key_valid = 0) {
                return 401 '{"error": "Invalid API key"}';
                add_header Content-Type application/json;
            }

            proxy_pass http://ollama;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # Support for streaming
            proxy_set_header Connection '';
            proxy_buffering off;
            proxy_cache off;
            chunked_transfer_encoding on;
        }

        # Root endpoint
        location / {
            return 200 '{"status": "online", "message": "Ollama API Gateway - Use /v1/chat/completions endpoint with Authorization: Bearer YOUR_API_KEY"}';
            add_header Content-Type application/json;
        }
    }
}
